{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKnHH06FNtVVEdSveJGrpR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install matplotlib numpy pylzma ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndysycC6J_1_",
        "outputId": "ef708e12-3cfc-4f68-a575-969587f03626"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting pylzma\n",
            "  Downloading pylzma-0.5.0.tar.gz (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (24.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.13)\n",
            "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Building wheels for collected packages: pylzma\n",
            "  Building wheel for pylzma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylzma: filename=pylzma-0.5.0-cp310-cp310-linux_x86_64.whl size=222322 sha256=89cad859e08419f85b5f641d62743b5f615d86f2f499c1a18aaf54228353ed0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/c9/02/91112815e838f544c1d46fda071241e454694579d022751d2b\n",
            "Successfully built pylzma\n",
            "Installing collected packages: pylzma, jedi\n",
            "Successfully installed jedi-0.19.1 pylzma-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "******************START OF CODE******************"
      ],
      "metadata": {
        "id": "8abZ5V1CMsNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram model and playing around ::"
      ],
      "metadata": {
        "id": "qrbAMTIHNMBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#print(device)\n",
        "\n",
        "block_size = 8\n",
        "batch_size = 4"
      ],
      "metadata": {
        "id": "bI2IcpImQIXj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"wizard of oz for llm.txt\", 'r', encoding='utf-8') as f: #open smaple training data file as read with utf 8 encoding\n",
        "  text = f.read()\n",
        "chars = sorted(set(text)) #creates a sorted list of all used characters\n",
        "print(chars)\n",
        "vocabulary_size = len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaSNmRGWK5b_",
        "outputId": "886491fc-7b64-44fd-9fc5-edd20397ea97"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = { ch:i for i,ch in enumerate(chars) } #mappings for str to int and vice versa\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) } # above\n",
        "encode = lambda s: [string_to_int[c] for c in s] #encoder\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l]) #decoder\n",
        "\n",
        "#example NOT actual code, comment out when not testing/demo-ing =>\n",
        "\n",
        "'''encoded_hello = encode('hello') #encode string 'hello' to integars\n",
        "decoded_hello = decode(encoded_hello)\n",
        "print(encoded_hello)\n",
        "print(decoded_hello)'''\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUiU5EUxODq4",
        "outputId": "6d5f11c0-fe05-4241-bfe0-99873e8551f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([79, 32, 72,  5, 71,  1, 66, 67,  1, 73, 71, 57, 22,  1, 66, 67,  1, 73,\n",
            "        71, 57,  1, 53, 72,  1, 53, 64, 64, 10,  1, 43, 60, 57,  1, 55, 60, 61,\n",
            "        64, 56, 70, 57, 66,  1, 75, 67, 66,  5, 72,  1, 64, 57, 72,  1, 65, 57,\n",
            "         1, 71, 72, 67, 68,  1, 72, 57, 64, 64, 61, 66, 59,  1, 72, 53, 64, 57,\n",
            "        71,  0, 67, 58,  1, 72, 60, 57,  1, 35, 53, 66, 56,  1, 67, 58,  1, 38,\n",
            "        78, 10,  1, 32,  1, 63, 66, 67, 75,  1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  print(ix)\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y\n",
        "\n",
        "x, y = get_batch('train')\n",
        "print('inputs: ')\n",
        "# print(x.shape)\n",
        "print(x)\n",
        "print('targets: ')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dXmGyahSL2T",
        "outputId": "6f9082e7-f602-4577-b5b4-3c6469dcfc24"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 85872, 135534,  32309,  67503])\n",
            "inputs: \n",
            "tensor([[60, 57, 70,  1, 65, 67, 73, 72],\n",
            "        [67, 75,  1, 55, 53, 70, 57, 64],\n",
            "        [ 5, 56,  1, 63, 66, 67, 75, 66],\n",
            "        [61, 63, 57,  1, 72, 67,  1, 59]], device='cuda:0')\n",
            "targets: \n",
            "tensor([[57, 70,  1, 65, 67, 73, 72, 60],\n",
            "        [75,  1, 55, 53, 70, 57, 64, 57],\n",
            "        [56,  1, 63, 66, 67, 75, 66,  1],\n",
            "        [63, 57,  1, 72, 67,  1, 59, 67]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocabulary_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocabulary_size, vocabulary_size)\n",
        "\n",
        "  def forward(self, index, targets=None):\n",
        "    logits = self.token_embedding_table(index)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, index, max_new_tokens):\n",
        "    # index is (B,T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "      # get the predictions\n",
        "      logits, loss = self.forward(index)\n",
        "      # focus only on the last time step\n",
        "      logits = logits[:, -1, :] # becomes (B, C)\n",
        "      # apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      # sample from the distribution\n",
        "      index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      # append sampled index to the running sequence\n",
        "      index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
        "    return index\n",
        "\n",
        "model = BigramLanguageModel(vocabulary_size)\n",
        "m = model.to(device)\n",
        "\n",
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dprOILpdiMqj",
        "outputId": "01ccc69d-4fd4-4083-cdad-99f945b797b8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7z]j?,ge﻿S(YZ:].﻿6Bq(0\n",
            "hc41Aw﻿011-_J7;v\"B5rI?3hn (KaU&KBqKBQHo0?,zGT m﻿0v\"e-HEh1zzuApht-RltTEP?oB459C,!:mf\"M8!rGhnVZlMhZIo﻿8 Nar5cld9ZqgjqfslM8-)\"gYs:HF],P(J[bkuv;AI,s\"J:﻿QR4R-RXy;UoRkCfYbUC2(;M8lf\"U;sgCA&,NQaSXzukt-A\n",
            "lXXXxdoK]cEt40uC,3F&V05RlaY[VO25)KyDyt-RlO2albAwYbB!V1pQ﻿x7f[D_dYT-0-TPTmp:﻿XUBXKQ'dTelX]cqk323vhW.\n",
            "VYGg tU)?Jvr\"RP\n",
            "(SeP&ta-;OHFJ[q41!pzy﻿!DW.NL0vPPVDi'\n",
            "F]\"-K!.'GM_T-J,8r5_;VG&pj\"MdV17JG?' OLKyw(T1\"J7VU;3G7,[zvHL﻿r-6eJ[Qpo9﻿UUtdkEx3U;]ZRdDGM\"ZZ!T9Vc3﻿y::45jf;-6Gy6,ol3 56CKKK,mJgQ-j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "We7295vMndmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-V_jWA85ndRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CxW8PN-1ndEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s5BF-YTxnc3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch-examples / playing about"
      ],
      "metadata": {
        "id": "9Q7q4UvtVEcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "BpSjqju-VDux"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randint = torch.randint(-100, 100, (6,))\n",
        "randint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyrol33gVIHY",
        "outputId": "78d05b43-28e8-46cb-9688-1dcbf7ee2089"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-14,  60,   4, -99, -53, -86])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Vectors"
      ],
      "metadata": {
        "id": "WFjSOqW3bNbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# initialise an embedding layer\n",
        "vocab_size = 1000\n",
        "embedding_dim = 100\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "# create some input indices\n",
        "input_indices = torch.LongTensor([1, 5, 3, 2])\n",
        "\n",
        "# apply the embedding layer\n",
        "embedded_output = embedding(input_indices)\n",
        "\n",
        "# the output will be a tensor of shape (4, 100), where 4 is the number of inputs\n",
        "# and 100 is the dimensionality of the embedding vectors\n",
        "print(embedded_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaRra7BtbQEg",
        "outputId": "0628c491-0829-4418-ccc7-7352f1e52cda"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print('when input is', context, 'target is', target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWWq-dyfScgh",
        "outputId": "fed8b9a6-bea4-448e-922f-c7d8fe4e3963"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([79]) target is tensor(32)\n",
            "when input is tensor([79, 32]) target is tensor(72)\n",
            "when input is tensor([79, 32, 72]) target is tensor(5)\n",
            "when input is tensor([79, 32, 72,  5]) target is tensor(71)\n",
            "when input is tensor([79, 32, 72,  5, 71]) target is tensor(1)\n",
            "when input is tensor([79, 32, 72,  5, 71,  1]) target is tensor(66)\n",
            "when input is tensor([79, 32, 72,  5, 71,  1, 66]) target is tensor(67)\n",
            "when input is tensor([79, 32, 72,  5, 71,  1, 66, 67]) target is tensor(1)\n"
          ]
        }
      ]
    }
  ]
}